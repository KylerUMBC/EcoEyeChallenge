{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c75155",
   "metadata": {},
   "source": [
    "# Booz Allen Spring 2025 Codefest: Challenge 1 \n",
    "### Isaiah Byrd, Kyler Gelissen, David Ameh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf53e88a-a531-4ef9-8f93-abc1a0bfc7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyler\\.cache\\kagglehub\\datasets\\sumn2u\\garbage-classification-v2\\versions\\8\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n",
    "print(path)\n",
    "\n",
    "dataset_root = os.path.join(path, \"garbage-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17afb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory garbage_classification_dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory to store the dataset\n",
    "dataset_dir = \"garbage_classification_dataset\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    print(f\"Directory {dataset_dir} created.\")\n",
    "else:\n",
    "    pass\n",
    "    print(f\"Directory {dataset_dir} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596913e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Function to install a package\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"matplotlib\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"opencv-python\",\n",
    "    \"kagglehub\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "# Install each package if not already installed\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install(package)\n",
    "\n",
    "# Importing the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd0698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "#device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "#print(f\"Using device: {device}\")\n",
    "\n",
    "#Change the memory fraction to limit the GPU memory usage\n",
    "#Set the memory fraction of the total GPU memory\n",
    "memory_fraction = 0.80\n",
    "\n",
    "if(device.type == \"cuda\"):\n",
    "    print(\"GPU is available\")\n",
    "    th.cuda.set_memory_fraction(memory_fraction, device=device.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f23c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #Image needs to be resized to 224x224 for ResNet requirement\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #Standard normalization for ResNet\n",
    "])\n",
    "\n",
    "#Load the dataset\n",
    "complete_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transforms) \n",
    "dataset_size = len(complete_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a8d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 19762\n",
      "Train size: 15809\n",
      "Validation size: 1976\n",
      "Test size: 1977\n"
     ]
    }
   ],
   "source": [
    "#We are going to do a 80-10-10 split of the dataset to start\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "\n",
    "#Using random_split to split the dataset into train, validation and test sets\n",
    "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(complete_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array([sample[1] for sample in complete_dataset.samples])\n",
    "StratShuffleSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) #Still doing 80 - 10 10 (20)\n",
    "train_idx, val_test_index = next(StratShuffleSplit.split(np.zeros(dataset_size), targets))\n",
    "StratShuffleSplit_val_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42) #This splits the 20 into 10 and 10\n",
    "val_idx, test_idx = next(StratShuffleSplit_val_test.split(np.zeros(len(val_test_index)), targets[val_test_index]))\n",
    "\n",
    "train_dataset = th.utils.data.Subset(complete_dataset, train_idx)\n",
    "val_dataset = th.utils.data.Subset(complete_dataset, val_idx)\n",
    "test_dataset = th.utils.data.Subset(complete_dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names from dataset: ['battery', 'biological', 'cardboard', 'clothes', 'glass', 'metal', 'paper', 'plastic', 'shoes', 'trash']\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "#Creating the dataloaders\n",
    "batch_size = 64 #Update this if memory permits\n",
    "num_workers = 4 #Decrease if colab is mad\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "#Fixed the dataset classes so it doesn't need to be manually set\n",
    "class_names = complete_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Class names from dataset: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0653c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\Kyler/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 25.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT) #Using ResNet50 as the base model for transfer learning\n",
    "\n",
    "#This takes the last layer of the model and replaces it with a new one\n",
    "num_ftrs = model.fc.in_features \n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model = model.to(device) #Moving the model to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a51762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#Learning rate is set to 1e-4 as a starting point, update this if needed\n",
    "learning_rate = 1.e-4 \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7688f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50 #Updated if needed\n",
    "patience = 3 #Early stopping patience\n",
    "best_val_acc = 0.0\n",
    "epochs_without_improvement = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "train_accuracy_history = []\n",
    "val_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main training loop\n",
    "for epoch in  range(max_epochs):\n",
    "    model.train() #Sets the model to training mode\n",
    "    running_corrects, running_samples = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        #Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() #Backpropagation step\n",
    "        optimizer.step() #Optimizer step\n",
    "\n",
    "        #Get the stupid predictions\n",
    "        preds = th.argmax(outputs, dim=1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        running_corrects += np.sum(preds == labels)\n",
    "        running_samples += labels.shape[0]\n",
    "\n",
    "    #Calculate the accuracy\n",
    "    epoch_train_accuracy = running_corrects / running_samples\n",
    "    train_accuracy_history.append(epoch_train_accuracy)\n",
    "\n",
    "    #Validation step\n",
    "    model.eval() #Sets the model to evaluation mode\n",
    "    running_corrects = 0\n",
    "    running_samples = 0\n",
    "    with th.no_grad(): #Disables gradient calculation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            preds = th.argmax(outputs, dim=1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            running_corrects += np.sum(preds == labels)\n",
    "            running_samples += labels.shape[0]\n",
    "\n",
    "    #Calculate the accuracy\n",
    "    epoch_val_accuracy = running_corrects / running_samples\n",
    "    val_accuracy_history.append(epoch_val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs} - Train accuracy: {epoch_train_accuracy:.4f} - Validation accuracy: {epoch_val_accuracy:.4f}\")\n",
    "\n",
    "    #Early stopping block\n",
    "    if epoch_val_accuracy  > best_val_acc:\n",
    "        best_val_acc = epoch_val_accuracy\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation accuracy for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "train_accuracy_history = np.array(train_accuracy_history)\n",
    "val_accuracy_history = np.array(val_accuracy_history)\n",
    "\n",
    "#Saves it\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the training and validation accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "epochs = np.arange(1, len(train_accuracy_history) + 1)\n",
    "plt.plot(epochs, train_accuracy_history, label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracy_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829bdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test loop\n",
    "model.eval()\n",
    "running_corrects = 0\n",
    "running_samples = 0\n",
    "with th.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = th.argmax(outputs, dim=1)\n",
    "        running_corrects += th.sum(preds == labels).item()  #More efficient on GPU\n",
    "        running_samples += labels.size(0)\n",
    "test_acc = running_corrects / running_samples\n",
    "print(f\"Test Accuracy (full set): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the model\n",
    "model_path = \"garbage_classification_model.pth\"\n",
    "th.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display a batch of images\n",
    "with th.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = th.argmax(outputs, dim=1)\n",
    "        images = inputs.cpu().numpy()  #Shape:(batch_size, 3, 224, 224)\n",
    "        actual_labels = labels.cpu().numpy()\n",
    "        predicted_labels = preds.cpu().numpy()\n",
    "        break  #One batch for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to denormalize the images to display them\n",
    "def denormalize(image):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    #This rescales the image to the original range\n",
    "    image = image * std[:, None, None] + mean[:, None, None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = random.sample(range(len(images)), 6)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    image = images[idx]  #Shape: (3, 224, 224)\n",
    "    actual = class_names[actual_labels[idx]]\n",
    "    predicted = class_names[predicted_labels[idx]]\n",
    "    \n",
    "    #Denormalize and transpose image to (H, W, C) for Matplotlib\n",
    "    image = denormalize(image)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = np.clip(image, 0, 1)  #Ensure pixel values are between 0 and 1\n",
    "    \n",
    "    #Display the image\n",
    "    axes[i].imshow(image)\n",
    "    \n",
    "    #Set title with actual and predicted (green if correct, red if incorrect)\n",
    "    title_color = 'green' if actual == predicted else 'red'\n",
    "    axes[i].set_title(f\"Actual: {actual}\\nPredicted: {predicted}\", \n",
    "                      color=title_color, \n",
    "                      fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "#Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc296c1e",
   "metadata": {},
   "source": [
    "### GUI for uploading an image to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7bcf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter.ttk import Button\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from PIL import Image, ImageTk, UnidentifiedImageError\n",
    "\n",
    "CANV_WIDTH, CANV_HEIGHT = 600, 500\n",
    "\n",
    "class ImageUploader:\n",
    "    def __init__(self, master=None):\n",
    "        \"\"\"\n",
    "        Initialize the ImageUploader class.\n",
    "        \n",
    "        If master is None, it creates a new Tkinter window.\n",
    "        Otherwise, it uses the provided master window (for embedding in another program).\n",
    "        \"\"\"\n",
    "        self.master = master or tk.Tk()\n",
    "        self.master.title(\"Image Uploader\")\n",
    "        self.master.geometry(f\"{600}x{550}\")\n",
    "\n",
    "        self.canvas = tk.Canvas(self.master, width=CANV_WIDTH, height=CANV_HEIGHT, bg=\"white\")\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.btn = Button(self.master, text=\"Upload Image\", command=self.upload_image)\n",
    "        self.btn.pack()\n",
    "\n",
    "        if master is None:  # Only run mainloop if this is the main script\n",
    "            self.master.mainloop()\n",
    "\n",
    "    def upload_image(self):\n",
    "        \"\"\"Handles the image upload and display process.\"\"\"\n",
    "        try:\n",
    "            img_path = askopenfilename()  # Open file dialog to select an image\n",
    "            if not img_path:\n",
    "                return  # If no file is selected, exit function\n",
    "\n",
    "            im = Image.open(img_path)  # Open image using PIL\n",
    "            img_width, img_height = im.size  # Get image dimensions\n",
    "\n",
    "            if img_width > 224 or img_height > 224:  # Resize image if too large\n",
    "                while img_width > CANV_WIDTH or img_height > CANV_HEIGHT:\n",
    "                    img_width *= 0.99\n",
    "                    img_height *= 0.99\n",
    "\n",
    "                im = im.resize((int(img_width), int(img_height)))\n",
    "                messagebox.showinfo(\"Image Resized\", \"The image has been resized to fit the model\")\n",
    "\n",
    "            img = ImageTk.PhotoImage(im)  # Convert image to Tkinter format\n",
    "            self.canvas.image = img  # Keep reference to image\n",
    "            self.canvas.create_image(CANV_WIDTH/2, CANV_HEIGHT/2, image=img, anchor=tk.CENTER)  # Display image on canvas\n",
    "\n",
    "        except UnidentifiedImageError:\n",
    "            messagebox.showinfo(\"Error\", \"Invalid file type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet50(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgarbage_classification_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Returns the predicted class of the image\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     ):\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[0;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         )\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[0;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1903\u001b[0m )\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:631\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    629\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 631\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Kyler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:600\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    598\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    608\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from google.colab import files  # For file uploads in Colab\n",
    "\n",
    "# 1) Define device and load model\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_names = complete_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.load_state_dict(th.load(\"garbage_classification_model.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(pil_image):\n",
    "    #Move to device\n",
    "    image_tensor = data_transforms(pil_image).unsqueeze(0).to(device)\n",
    "    with th.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = th.max(output, 1)\n",
    "    return class_names[predicted.item()]\n",
    "\n",
    "\n",
    "uploaded = files.upload() \n",
    "img_path = list(uploaded.keys())[0]  \n",
    "\n",
    "# 5) Open it, predict, and display\n",
    "uploaded_image = Image.open(img_path).convert(\"RGB\")\n",
    "predicted_class = predict_image(uploaded_image)\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "plt.imshow(np.array(uploaded_image))\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
