{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c75155",
   "metadata": {},
   "source": [
    "# Booz Allen Spring 2025 Codefest: Challenge 1 \n",
    "### Isaiah Byrd, Kyler Gelissen, David Ameh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf53e88a-a531-4ef9-8f93-abc1a0bfc7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyler\\.cache\\kagglehub\\datasets\\sumn2u\\garbage-classification-v2\\versions\\8\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n",
    "print(path)\n",
    "\n",
    "dataset_root = os.path.join(path, \"garbage-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17afb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory garbage_classification_dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory to store the dataset\n",
    "dataset_dir = \"garbage_classification_dataset\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    print(f\"Directory {dataset_dir} created.\")\n",
    "else:\n",
    "    pass\n",
    "    print(f\"Directory {dataset_dir} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596913e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "#Function to install a package\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "#List of required packages\n",
    "required_packages = [\n",
    "    \"matplotlib\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"opencv-python\",\n",
    "    \"kagglehub\"\n",
    "]\n",
    "\n",
    "# Install each package if not already installed\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install(package)\n",
    "\n",
    "# Importing the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fd0698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Set device to GPU if available\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#Change the memory fraction to limit the GPU memory usage\n",
    "#Set the memory fraction of the total GPU memory\n",
    "memory_fraction = 0.80\n",
    "\n",
    "if(device.type == \"cuda\"):\n",
    "    print(\"GPU is available\")\n",
    "    th.cuda.set_memory_fraction(memory_fraction, device=device.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f23c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), #Image needs to be resized to 224x224 for ResNet requirement\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #Standard normalization for ResNet\n",
    "])\n",
    "\n",
    "#Load the dataset\n",
    "complete_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transforms) \n",
    "dataset_size = len(complete_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a8d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 19762\n",
      "Train size: 15809\n",
      "Validation size: 1976\n",
      "Test size: 1977\n"
     ]
    }
   ],
   "source": [
    "#We are going to do a 80-10-10 split of the dataset to start\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "\n",
    "#Using random_split to split the dataset into train, validation and test sets\n",
    "train_dataset, val_dataset, test_dataset = th.utils.data.random_split(complete_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bde1f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataloaders\n",
    "batch_size = 64 #Update this if memory permits\n",
    "num_workers = 4 #Decrease if colab is mad\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "#Fixed the dataset classes so it doesn't need to be manually set\n",
    "class_names = complete_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Class names from dataset: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e0653c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyler\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kyler\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Kyler/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 25.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True) #Using ResNet50 as the base model for transfer learning\n",
    "\n",
    "#This takes the last layer of the model and replaces it with a new one\n",
    "num_ftrs = model.fc.in_features \n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model = model.to(device) #Moving the model to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a51762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#Learning rate is set to 1e-4 as a starting point, update this if needed\n",
    "learning_rate = 1.e-4 \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7688f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_empochs = 2 #Update this if needed\n",
    "train_accuracy_history = []\n",
    "val_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main training loop\n",
    "for epoch in  range(num_empochs):\n",
    "    model.train() #Sets the model to training mode\n",
    "    running_corrects = 0\n",
    "    running_samples = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        #Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() #Backpropagation step\n",
    "        optimizer.step() #Optimizer step\n",
    "\n",
    "        #Get the stupid predictions\n",
    "        preds = th.argmax(outputs, dim=1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        running_corrects += np.sum(preds == labels)\n",
    "        running_samples += labels.shape[0]\n",
    "    \n",
    "    #Calculate the accuracy\n",
    "    epoch_train_accuracy = running_corrects / running_samples\n",
    "    train_accuracy_history.append(epoch_train_accuracy)\n",
    "\n",
    "    #Validation step\n",
    "    model.eval() #Sets the model to evaluation mode\n",
    "    running_corrects = 0\n",
    "    running_samples = 0\n",
    "    with th.no_grad(): #Disables gradient calculation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            preds = th.argmax(outputs, dim=1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            running_corrects += np.sum(preds == labels)\n",
    "            running_samples += labels.shape[0]\n",
    "\n",
    "    #Calculate the accuracy\n",
    "    epoch_val_accuracy = running_corrects / running_samples\n",
    "    val_accuracy_history.append(epoch_val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_empochs} - Train accuracy: {epoch_train_accuracy:.4f} - Validation accuracy: {epoch_val_accuracy:.4f}\")\n",
    "\n",
    "train_accuracy_history = np.array(train_accuracy_history)\n",
    "val_accuracy_history = np.array(val_accuracy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33a7a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to denormalize the images to display them\n",
    "def denormalize(image):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    #This rescales the image to the original range\n",
    "    image = image * std[:, None, None] + mean[:, None, None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829bdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test loop\n",
    "model.eval()\n",
    "running_corrects = 0\n",
    "running_samples = 0\n",
    "with th.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = th.argmax(outputs, dim=1)\n",
    "        preds_np = preds.cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "        running_corrects += np.sum(preds_np == labels_np)\n",
    "        running_samples += labels_np.shape[0]\n",
    "        \n",
    "        #Capture only one batch for visualization\n",
    "        if 'images' not in locals():\n",
    "            images = inputs.cpu().numpy()  #Shape: (batch_size, 3, 224, 224)\n",
    "            actual_labels = labels_np\n",
    "            predicted_labels = preds_np\n",
    "            break  #Use only one batch for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cb2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
